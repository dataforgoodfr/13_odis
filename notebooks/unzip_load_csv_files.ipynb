{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aee0f389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing to parent dir\n",
      "/Users/alex/dev/13_odis\n"
     ]
    }
   ],
   "source": [
    "# Manage all imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "# Dirty trick to be able to import common odis modules, if the notebook is not executed from 13_odis\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "while not current_dir.endswith(\"13_odis\"):\n",
    "    print(\"changing to parent dir\")\n",
    "    os.chdir(parent_dir)\n",
    "    current_dir = parent_dir\n",
    "    parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "print(os.getcwd())\n",
    "sys.path.append(current_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f19fac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# additional imports\n",
    "from common.config import load_config\n",
    "from common.data_source_model import DataSourceModel\n",
    "from common.utils.file_handler import FileHandler\n",
    "from common.utils.interfaces.data_handler import OperationType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4c15cb",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# define parameters for papermill\n",
    "\n",
    "# model_name = \"emploi.salaire_median\"\n",
    "# filepath = 'data/imports/emploi/emploi.salaire_median_1.zip'\n",
    "\n",
    "model_name = \"emploi.deplacement_domicile_travail\"\n",
    "filepath = 'data/imports/emploi/emploi.deplacement_domicile_travail_1.zip'\n",
    "\n",
    "# model_name = \"emploi.etablissements_employeurs_secteur_prive\"\n",
    "# filepath = 'data/imports/emploi/emploi.etablissements_employeurs_secteur_prive_1.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fadac0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize common variables\n",
    "dataframes = {}\n",
    "artifacts = []\n",
    "\n",
    "config = load_config(\"datasources.yaml\", response_model=DataSourceModel)\n",
    "model = config.get_model( model_name = model_name )\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# Instantiate File Handler for file loads and dumps\n",
    "handler = FileHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a54a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtable_name(dfname:str, model:DataSourceModel) -> str:\n",
    "\n",
    "    subtable_name = ''\n",
    "\n",
    "    long_name = f\"{model.table_name}_{dfname.lower()}\"\n",
    "\n",
    "    print(len(long_name))\n",
    "\n",
    "    if len(long_name) >= 63:\n",
    "        print(f\"Long table name exceeds the 63 characters limit: {long_name}\")\n",
    "        subtable_name = f\"{model.domain_name}_{dfname.lower()}\"\n",
    "        print(f\"Creating table with shorter name: {subtable_name}\")\n",
    "        print(f\"Shorter table name length: {len(subtable_name)}\")\n",
    "    else:\n",
    "        subtable_name = long_name\n",
    "\n",
    "    return subtable_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5ebbd6-1ec4-4e45-8890-1155ea52684c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv\n",
      "2025-05-18 00:08:05,836 - DEBUG :: file_handler.py :: dump (130) :: dumping: data/imports/emploi/emploi.salaire_median_FILO2021_DEC_COM.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-18 00:08:05,915 - DEBUG :: file_handler.py :: file_dump (273) :: emploi.salaire_median -> results saved to : 'data/imports/emploi/emploi.salaire_median_FILO2021_DEC_COM.csv'\n",
      "{'name': 'FILO2021_DEC_COM', 'storage_info': {'location': 'data/imports/emploi', 'format': 'csv', 'file_name': 'emploi.salaire_median_FILO2021_DEC_COM.csv', 'encoding': 'utf-8'}, 'load_to_bronze': True, 'success': True}\n",
      "csv\n",
      "2025-05-18 00:08:05,925 - DEBUG :: file_handler.py :: dump (130) :: dumping: data/imports/emploi/emploi.salaire_median_FILO2021_DEC_PAUVRES_COM.csv\n",
      "2025-05-18 00:08:05,942 - DEBUG :: file_handler.py :: file_dump (273) :: emploi.salaire_median -> results saved to : 'data/imports/emploi/emploi.salaire_median_FILO2021_DEC_PAUVRES_COM.csv'\n",
      "{'name': 'FILO2021_DEC_PAUVRES_COM', 'storage_info': {'location': 'data/imports/emploi', 'format': 'csv', 'file_name': 'emploi.salaire_median_FILO2021_DEC_PAUVRES_COM.csv', 'encoding': 'utf-8'}, 'load_to_bronze': True, 'success': True}\n",
      "csv\n",
      "2025-05-18 00:08:06,007 - DEBUG :: file_handler.py :: dump (130) :: dumping: data/imports/emploi/emploi.salaire_median_FILO2021_DISP_COM.csv\n",
      "2025-05-18 00:08:06,095 - DEBUG :: file_handler.py :: file_dump (273) :: emploi.salaire_median -> results saved to : 'data/imports/emploi/emploi.salaire_median_FILO2021_DISP_COM.csv'\n",
      "{'name': 'FILO2021_DISP_COM', 'storage_info': {'location': 'data/imports/emploi', 'format': 'csv', 'file_name': 'emploi.salaire_median_FILO2021_DISP_COM.csv', 'encoding': 'utf-8'}, 'load_to_bronze': True, 'success': True}\n",
      "csv\n",
      "2025-05-18 00:08:06,100 - DEBUG :: file_handler.py :: dump (130) :: dumping: data/imports/emploi/emploi.salaire_median_FILO2021_DISP_PAUVRES_COM.csv\n",
      "2025-05-18 00:08:06,107 - DEBUG :: file_handler.py :: file_dump (273) :: emploi.salaire_median -> results saved to : 'data/imports/emploi/emploi.salaire_median_FILO2021_DISP_PAUVRES_COM.csv'\n",
      "{'name': 'FILO2021_DISP_PAUVRES_COM', 'storage_info': {'location': 'data/imports/emploi', 'format': 'csv', 'file_name': 'emploi.salaire_median_FILO2021_DISP_PAUVRES_COM.csv', 'encoding': 'utf-8'}, 'load_to_bronze': True, 'success': True}\n",
      "csv\n",
      "2025-05-18 00:08:06,112 - DEBUG :: file_handler.py :: dump (130) :: dumping: data/imports/emploi/emploi.salaire_median_FILO2021_TRDECILES_DEC_COM.csv\n",
      "2025-05-18 00:08:06,115 - DEBUG :: file_handler.py :: file_dump (273) :: emploi.salaire_median -> results saved to : 'data/imports/emploi/emploi.salaire_median_FILO2021_TRDECILES_DEC_COM.csv'\n",
      "{'name': 'FILO2021_TRDECILES_DEC_COM', 'storage_info': {'location': 'data/imports/emploi', 'format': 'csv', 'file_name': 'emploi.salaire_median_FILO2021_TRDECILES_DEC_COM.csv', 'encoding': 'utf-8'}, 'load_to_bronze': True, 'success': True}\n",
      "csv\n",
      "2025-05-18 00:08:06,121 - DEBUG :: file_handler.py :: dump (130) :: dumping: data/imports/emploi/emploi.salaire_median_FILO2021_TRDECILES_DISP_COM.csv\n",
      "2025-05-18 00:08:06,133 - DEBUG :: file_handler.py :: file_dump (273) :: emploi.salaire_median -> results saved to : 'data/imports/emploi/emploi.salaire_median_FILO2021_TRDECILES_DISP_COM.csv'\n",
      "{'name': 'FILO2021_TRDECILES_DISP_COM', 'storage_info': {'location': 'data/imports/emploi', 'format': 'csv', 'file_name': 'emploi.salaire_median_FILO2021_TRDECILES_DISP_COM.csv', 'encoding': 'utf-8'}, 'load_to_bronze': True, 'success': True}\n",
      "csv\n",
      "2025-05-18 00:08:06,136 - DEBUG :: file_handler.py :: dump (130) :: dumping: data/imports/emploi/emploi.salaire_median_meta_FILO2021_DEC_COM.csv\n",
      "2025-05-18 00:08:06,138 - DEBUG :: file_handler.py :: file_dump (273) :: emploi.salaire_median -> results saved to : 'data/imports/emploi/emploi.salaire_median_meta_FILO2021_DEC_COM.csv'\n",
      "{'name': 'meta_FILO2021_DEC_COM', 'storage_info': {'location': 'data/imports/emploi', 'format': 'csv', 'file_name': 'emploi.salaire_median_meta_FILO2021_DEC_COM.csv', 'encoding': 'utf-8'}, 'load_to_bronze': True, 'success': True}\n",
      "csv\n",
      "2025-05-18 00:08:06,142 - DEBUG :: file_handler.py :: dump (130) :: dumping: data/imports/emploi/emploi.salaire_median_meta_FILO2021_DEC_PAUVRES_COM.csv\n",
      "2025-05-18 00:08:06,145 - DEBUG :: file_handler.py :: file_dump (273) :: emploi.salaire_median -> results saved to : 'data/imports/emploi/emploi.salaire_median_meta_FILO2021_DEC_PAUVRES_COM.csv'\n",
      "{'name': 'meta_FILO2021_DEC_PAUVRES_COM', 'storage_info': {'location': 'data/imports/emploi', 'format': 'csv', 'file_name': 'emploi.salaire_median_meta_FILO2021_DEC_PAUVRES_COM.csv', 'encoding': 'utf-8'}, 'load_to_bronze': True, 'success': True}\n",
      "csv\n",
      "2025-05-18 00:08:06,149 - DEBUG :: file_handler.py :: dump (130) :: dumping: data/imports/emploi/emploi.salaire_median_meta_FILO2021_DISP_COM.csv\n",
      "2025-05-18 00:08:06,151 - DEBUG :: file_handler.py :: file_dump (273) :: emploi.salaire_median -> results saved to : 'data/imports/emploi/emploi.salaire_median_meta_FILO2021_DISP_COM.csv'\n",
      "{'name': 'meta_FILO2021_DISP_COM', 'storage_info': {'location': 'data/imports/emploi', 'format': 'csv', 'file_name': 'emploi.salaire_median_meta_FILO2021_DISP_COM.csv', 'encoding': 'utf-8'}, 'load_to_bronze': True, 'success': True}\n",
      "csv\n",
      "2025-05-18 00:08:06,154 - DEBUG :: file_handler.py :: dump (130) :: dumping: data/imports/emploi/emploi.salaire_median_meta_FILO2021_DISP_PAUVRES_COM.csv\n",
      "2025-05-18 00:08:06,157 - DEBUG :: file_handler.py :: file_dump (273) :: emploi.salaire_median -> results saved to : 'data/imports/emploi/emploi.salaire_median_meta_FILO2021_DISP_PAUVRES_COM.csv'\n",
      "{'name': 'meta_FILO2021_DISP_PAUVRES_COM', 'storage_info': {'location': 'data/imports/emploi', 'format': 'csv', 'file_name': 'emploi.salaire_median_meta_FILO2021_DISP_PAUVRES_COM.csv', 'encoding': 'utf-8'}, 'load_to_bronze': True, 'success': True}\n",
      "csv\n",
      "2025-05-18 00:08:06,161 - DEBUG :: file_handler.py :: dump (130) :: dumping: data/imports/emploi/emploi.salaire_median_meta_FILO2021_TRDECILES_DEC_COM.csv\n",
      "2025-05-18 00:08:06,164 - DEBUG :: file_handler.py :: file_dump (273) :: emploi.salaire_median -> results saved to : 'data/imports/emploi/emploi.salaire_median_meta_FILO2021_TRDECILES_DEC_COM.csv'\n",
      "{'name': 'meta_FILO2021_TRDECILES_DEC_COM', 'storage_info': {'location': 'data/imports/emploi', 'format': 'csv', 'file_name': 'emploi.salaire_median_meta_FILO2021_TRDECILES_DEC_COM.csv', 'encoding': 'utf-8'}, 'load_to_bronze': True, 'success': True}\n",
      "csv\n",
      "2025-05-18 00:08:06,167 - DEBUG :: file_handler.py :: dump (130) :: dumping: data/imports/emploi/emploi.salaire_median_meta_FILO2021_TRDECILES_DISP_COM.csv\n",
      "2025-05-18 00:08:06,170 - DEBUG :: file_handler.py :: file_dump (273) :: emploi.salaire_median -> results saved to : 'data/imports/emploi/emploi.salaire_median_meta_FILO2021_TRDECILES_DISP_COM.csv'\n",
      "{'name': 'meta_FILO2021_TRDECILES_DISP_COM', 'storage_info': {'location': 'data/imports/emploi', 'format': 'csv', 'file_name': 'emploi.salaire_median_meta_FILO2021_TRDECILES_DISP_COM.csv', 'encoding': 'utf-8'}, 'load_to_bronze': True, 'success': True}\n"
     ]
    }
   ],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "# unzip and dump files into the data/imports folder\n",
    "with open(filepath, 'rb') as f:\n",
    "    zip_archive = ZipFile(f)\n",
    "\n",
    "    zip_members = zip_archive.infolist()\n",
    "    for member in zip_members:\n",
    "\n",
    "        if not member.is_dir():\n",
    "\n",
    "            member_filename = member.filename\n",
    "            member_name = member_filename.split(\".\")[0]\n",
    "            member_format = member_filename.split(\".\")[-1]\n",
    "            print(member_format)\n",
    "            \n",
    "            f_member = zip_archive.open( member, 'r' ).read()\n",
    "    \n",
    "            artifact = handler.artifact_dump(\n",
    "                f_member,\n",
    "                get_subtable_name(member_name,model),\n",
    "                model,\n",
    "                format = member_format\n",
    "            )\n",
    "\n",
    "            print(artifact.model_dump(mode=\"yaml\"))\n",
    "\n",
    "            artifacts.append(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0e95b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-18 00:08:07,854 - DEBUG :: file_handler.py :: dump (130) :: dumping: data/imports/emploi/emploi.salaire_median_metadata_preprocess.json\n",
      "2025-05-18 00:08:07,858 - DEBUG :: file_handler.py :: file_dump (273) :: emploi.salaire_median -> results saved to : 'data/imports/emploi/emploi.salaire_median_metadata_preprocess.json'\n",
      "2025-05-18 00:08:07,859 - DEBUG :: file_handler.py :: dump_metadata (455) :: Metadata written in: 'data/imports/emploi/emploi.salaire_median_metadata_preprocess.json'\n"
     ]
    }
   ],
   "source": [
    "preprocess_metadata = handler.dump_metadata(\n",
    "    model = model,\n",
    "    operation = OperationType.PREPROCESS,\n",
    "    start_time = start_time,\n",
    "    complete = True,\n",
    "    errors = 0,\n",
    "    artifacts = artifacts,\n",
    "    pages = []\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e35462b-bcc3-4f98-84d7-f71e8cb7873f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ArtifactLog' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      8\u001b[39m     df = pd.read_csv(\n\u001b[32m      9\u001b[39m         filepath,\n\u001b[32m     10\u001b[39m         sep = \u001b[33m'\u001b[39m\u001b[33m;\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     11\u001b[39m         engine = \u001b[33m'\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     12\u001b[39m         )\n\u001b[32m     14\u001b[39m     dataframes[ artifact.name ] = df\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43martifacts\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhead\u001b[49m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/13_odis/.venv/lib/python3.12/site-packages/pydantic/main.py:994\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    991\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    992\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    993\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m994\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'ArtifactLog' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "for artifact in artifacts:\n",
    "\n",
    "    base_path = Path( artifact.storage_info.location )\n",
    "    filepath = base_path / artifact.storage_info.file_name\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        filepath,\n",
    "        sep = ';',\n",
    "        engine = 'python'\n",
    "        )\n",
    "\n",
    "    dataframes[ artifact.name ] = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46761043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataframes:\n",
      "FILO2021_DEC_COM\n",
      "FILO2021_DEC_PAUVRES_COM\n",
      "FILO2021_DISP_COM\n",
      "FILO2021_DISP_PAUVRES_COM\n",
      "FILO2021_TRDECILES_DEC_COM\n",
      "FILO2021_TRDECILES_DISP_COM\n",
      "meta_FILO2021_DEC_COM\n",
      "meta_FILO2021_DEC_PAUVRES_COM\n",
      "meta_FILO2021_DISP_COM\n",
      "meta_FILO2021_DISP_PAUVRES_COM\n",
      "meta_FILO2021_TRDECILES_DEC_COM\n",
      "meta_FILO2021_TRDECILES_DISP_COM\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODGEO</th>\n",
       "      <th>NBMEN21</th>\n",
       "      <th>NBPERS21</th>\n",
       "      <th>NBUC21</th>\n",
       "      <th>Q121</th>\n",
       "      <th>Q221</th>\n",
       "      <th>Q321</th>\n",
       "      <th>Q3_Q1</th>\n",
       "      <th>D121</th>\n",
       "      <th>D221</th>\n",
       "      <th>...</th>\n",
       "      <th>OPR6PTSA21</th>\n",
       "      <th>OPR6PCHO21</th>\n",
       "      <th>OPR6PBEN21</th>\n",
       "      <th>OPR6PPEN21</th>\n",
       "      <th>OPR6PPAT21</th>\n",
       "      <th>OPR6PPSOC21</th>\n",
       "      <th>OPR6PPFAM21</th>\n",
       "      <th>OPR6PPMINI21</th>\n",
       "      <th>OPR6PPLOGT21</th>\n",
       "      <th>OPR6PIMPOT21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>346</td>\n",
       "      <td>895</td>\n",
       "      <td>590,8</td>\n",
       "      <td>s</td>\n",
       "      <td>25820</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01002</td>\n",
       "      <td>115</td>\n",
       "      <td>266</td>\n",
       "      <td>181,0</td>\n",
       "      <td>s</td>\n",
       "      <td>24480</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01004</td>\n",
       "      <td>6855</td>\n",
       "      <td>15092</td>\n",
       "      <td>10398,2</td>\n",
       "      <td>15800</td>\n",
       "      <td>21660</td>\n",
       "      <td>28430</td>\n",
       "      <td>12630</td>\n",
       "      <td>11890</td>\n",
       "      <td>14640</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01005</td>\n",
       "      <td>800</td>\n",
       "      <td>2028</td>\n",
       "      <td>1329,7</td>\n",
       "      <td>20010</td>\n",
       "      <td>24610</td>\n",
       "      <td>31180</td>\n",
       "      <td>11170</td>\n",
       "      <td>15560</td>\n",
       "      <td>18980</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01006</td>\n",
       "      <td>51</td>\n",
       "      <td>107</td>\n",
       "      <td>76,6</td>\n",
       "      <td>s</td>\n",
       "      <td>24210</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 732 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CODGEO NBMEN21 NBPERS21   NBUC21   Q121   Q221   Q321  Q3_Q1   D121   D221  \\\n",
       "0  01001     346      895    590,8      s  25820      s      s      s      s   \n",
       "1  01002     115      266    181,0      s  24480      s      s      s      s   \n",
       "2  01004    6855    15092  10398,2  15800  21660  28430  12630  11890  14640   \n",
       "3  01005     800     2028   1329,7  20010  24610  31180  11170  15560  18980   \n",
       "4  01006      51      107     76,6      s  24210      s      s      s      s   \n",
       "\n",
       "   ... OPR6PTSA21 OPR6PCHO21 OPR6PBEN21 OPR6PPEN21 OPR6PPAT21 OPR6PPSOC21  \\\n",
       "0  ...          s          s          s          s          s           s   \n",
       "1  ...          s          s          s          s          s           s   \n",
       "2  ...          s          s          s          s          s           s   \n",
       "3  ...          s          s          s          s          s           s   \n",
       "4  ...          s          s          s          s          s           s   \n",
       "\n",
       "  OPR6PPFAM21 OPR6PPMINI21 OPR6PPLOGT21 OPR6PIMPOT21  \n",
       "0           s            s            s            s  \n",
       "1           s            s            s            s  \n",
       "2           s            s            s            s  \n",
       "3           s            s            s            s  \n",
       "4           s            s            s            s  \n",
       "\n",
       "[5 rows x 732 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Loaded dataframes:\")\n",
    "last_key = ''\n",
    "for key in dataframes.keys():\n",
    "    last_key = key\n",
    "    print(key)\n",
    "\n",
    "dataframes[last_key].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26f122f2-89aa-4c2c-a124-83dead75c61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "import sqlalchemy\n",
    "\n",
    "# prepare db client\n",
    "vals = dotenv_values()\n",
    "\n",
    "conn_str = \"postgresql://{}:{}@{}:{}/{}\".format(\n",
    "    vals[\"PG_DB_USER\"],\n",
    "    vals[\"PG_DB_PWD\"],\n",
    "    vals[\"PG_DB_HOST\"],\n",
    "    vals[\"PG_DB_PORT\"],\n",
    "    vals[\"PG_DB_NAME\"]\n",
    ")\n",
    "\n",
    "dbengine = sqlalchemy.create_engine(conn_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e43fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert all to bronze\n",
    "# make the final table name lowercase to avoid issues in Postgre\n",
    "for dfname, dataframe in dataframes.items():\n",
    "    dataframe.to_sql(\n",
    "        name = dfname,\n",
    "        con = dbengine,\n",
    "        schema = 'bronze',\n",
    "        index = True,\n",
    "        if_exists = 'replace'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8e6152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
