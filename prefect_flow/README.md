# ğŸ“˜ README â€“ ExÃ©cution du pipeline Prefect 3.6

Ce projet utilise **Prefect 3.6**, qui sÃ©pare nettement :

* lâ€™**API Orion** (serveur)
* le **DÃ©ploiement / Serveur de Flow**
* les **Workers** qui exÃ©cutent les tÃ¢ches

Câ€™est ce dÃ©coupage qui explique pourquoi **plusieurs terminaux** sont nÃ©cessaires.

---

# ğŸš€ 1. PrÃ©requis

CrÃ©er lâ€™environnement virtuel :

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
cd prefect_flow; docker compose up -d
prefect config set PREFECT_API_URL="http://127.0.0.1:4200/api"
prefect config set PREFECT_API_DATABASE_CONNECTION_URL="postgresql+asyncpg://prefect:prefect@localhost:5432/prefect"

```
Vous pourrez ensuite vÃ©rifier qu'aucun dossier storage/ est crÃ©Ã© dans ~/.prefect/

---

# ğŸ§  Architecture Prefect 3.6 â€” Pourquoi 3 terminaux ?

Prefect fonctionne selon trois rÃ´les complÃ©mentaires :

### ğŸ–¥ï¸ TERMINAL 1 â€” **Serveur Prefect (API + UI)**

Câ€™est le "cerveau".
Il stocke :

* les flows
* les runs
* lâ€™historique
* les logs
* les orchestrations

Sans le serveur â†’ impossible de dÃ©clencher un flow.

```bash
prefect server start
```

---

### âš™ï¸ TERMINAL 2 â€” **Flow Server (serve)**

Quand tu lances :

```bash
python -m prefect_flow.flow
```

ton code appelle :

```python
full_pipeline.serve()
```

Cela crÃ©e :

* un **deployment** (â€œfull-pipelineâ€)
* un **work pool** (default)
* un service qui dit au serveur : â€œjâ€™existe, voici ma dÃ©finition de flowâ€.

Ce terminal doit rester **ouvert** : câ€™est lui qui dÃ©clare ton flow au serveur.

---

### ğŸ­ TERMINAL 3 â€” **Worker**

Le worker exÃ©cute les runs.
Il se connecte au work pool et rÃ©cupÃ¨re les tÃ¢ches Ã  exÃ©cuter.

Il doit savoir oÃ¹ se trouve le serveur â†’ dâ€™oÃ¹ la variable :

```
PREFECT_API_URL=http://127.0.0.1:4200/api
```

Il doit tourner **en continu** comme un job supervisor.

```bash
export PREFECT_API_URL=http://127.0.0.1:4200/api ; prefect worker start -q default
```

---

### ğŸ•¹ï¸ TERMINAL 4 â€” **DÃ©clenchement dâ€™un run**

Ce terminal est optionnel : il sert uniquement Ã  lancer un run manuel.

```bash
prefect deployment run "full-pipeline/full_pipeline"
```


# DEBUG

if __name__ == "__main__":
    odis_pipeline(
        config_path="datasources.yaml",
        max_concurrency=4,
    )



Oui â€” ce log donne **lâ€™information clÃ©** qui manquait :
le problÃ¨me nâ€™est pas seulement la session aiohttp non fermÃ©e, mais aussi que tu passes **des objets nonâ€awaitables** dans ton `asyncio.gather()`.

Regarde :

```
TypeError: An asyncio.Future, a coroutine or an awaitable is required
```

et juste au-dessus :

```
artifacts = await asyncio.gather(*extract_tasks, return_exceptions=True)
                ^^^^^^^^^^^^^^^
```

Donc **`extract_tasks` ne contient pas des coroutines**â€¦ mais autre chose.

Et en regardant ton code, on comprend pourquoi ğŸ‘‡

---

# ğŸ’¥ Cause exacte

Tu construis ta liste ainsi :

```python
extract_tasks = [
    prefect_extract.with_options(name=f"Extract {ds.name}").submit(config, ds, max_concurrency)
    for ds in config.get_models().values()
]
```

Et **`.submit()` retourne un objet Prefect TaskRunResult**, pas une future asyncio.
Donc :

* `submit()` = exÃ©cution **async orchestrÃ©e par Prefect**, mais **pas une coroutine**
* `await asyncio.gather(...)` = attend **des coroutines Python**, pas des tÃ¢ches Prefect

Donc mÃ©langer les deux = âŒ crash.

---

# ğŸ§  ThÃ©orie Prefect (clair et simple)

Deux modÃ¨les existent :

## **ModÃ¨le 1 : Async Python**

* Tu appelles une `@task async`
* Tu rÃ©cupÃ¨res un `coroutine`
* Tu `await` avec `gather`

Exemple :

```python
tasks = [prefect_extract(...), prefect_extract(...)]
results = await asyncio.gather(*tasks)
```

## **ModÃ¨le 2 : Orchestration Prefect**

* Tu appelles `.submit()`
* Tu rÃ©cupÃ¨res un `PrefectFuture`
* Tu `.result()` (sync) ou `.wait()` (async)

Exemple :

```python
tasks = [prefect_extract.submit(...), prefect_extract.submit(...)]
results = [task.result() for task in tasks]
```

ğŸ‘‰ **NE JAMAIS mÃ©langer les deux modÃ¨les**.

Et câ€™est exactement ce que ton code fait aujourdâ€™hui.

---

# ğŸŸ¢ Comment corriger

Tu dois **choisir un modÃ¨le** :

---

## âœ”ï¸ Option A : Flow 100% async Python (recommandÃ© pour API / aiohttp)

### 1) Task async

```python
@task
async def prefect_extract(config, ds, max_concurrency):
    return await run_extraction(config, [ds], max_concurrency)
```

### 2) Flow async

```python
@flow
async def full_pipeline(...):
    config = load_config(...)

    tasks = [
        prefect_extract.with_options(name=f"Extract {ds.name}")(
            config, ds, max_concurrency
        )
        for ds in config.get_models().values()
    ]

    artifacts = await asyncio.gather(*tasks, return_exceptions=True)
```

ğŸ‘‰ Pas de `.submit()`.

* Prefect dÃ©tecte que ce sont des coroutines et les exÃ©cute dans un seul processus
* parfait si `run_extraction` fait de lâ€™I/O concurrent

---

## âœ”ï¸ Option B : Flow orchestrÃ© Prefect (pour scalabilitÃ© / workers)

Si tu veux lancer **chaque extraction sur un worker sÃ©parÃ©**, tu fais :

```python
tasks = [
    prefect_extract.with_options(name=f"Extract {ds.name}").submit(
        config, ds, max_concurrency
    )
    for ds in config.get_models().values()
]
```

Puis :

```python
artifacts = [t.result() for t in tasks]
```

ğŸ‘‰ Ici **pas de `await asyncio.gather()`**.

Câ€™est Prefect qui gÃ¨re le scheduling, lâ€™async, les retries, etc.
Ton flow reste **synchrone**, mais distribuÃ©.

---

# â— Ã€ propos de lâ€™erreur aiohttp Â« Unclosed client session Â»

Elle est probablement causÃ©e par :

* des sessions ouvertes dans `run_extraction`
* un mauvais pattern async
* lâ€™event loop forcÃ©e par Prefect

Quand tu corrigeras **lâ€™un des deux modÃ¨les**, lâ€™erreur a de grandes chances de disparaÃ®tre.

Mais vÃ©rifie quand mÃªme :

```python
async with aiohttp.ClientSession() as session:
    ...
```

(âŒ pas de `session = ClientSession()` sans close)

---

# ğŸ¯ Recommandation

Vu ton code, je pense que tu veux :

* plusieurs extracteurs en parallÃ¨le,
* mais dans **le mÃªme process**
* avec async+await rÃ©el
* sans worker Dist Prefect

Donc **Option A** est ton meilleur choix.

---

# âœ¨ RÃ©sumÃ© ultra court

Lâ€™erreur vient de :

```
.submit() + asyncio.gather() = incompatible
```

Corrige en :

* soit `await gather(tasks)` **sans submit**
* soit `submit()` **sans gather**

Et ta stack trace disparaÃ®t ğŸ’ª

---

Si tu veux, je peux te proposer une **version corrigÃ©e complÃ¨te de ton flow** + correction dans `run_extraction` pour fermer les sessions aiohttp proprement.
