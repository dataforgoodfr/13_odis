# ğŸ“˜ README â€“ ExÃ©cution du pipeline Prefect 3.6

Ce projet utilise **Prefect 3.6**, qui sÃ©pare nettement :

* lâ€™**API Orion** (serveur)
* le **DÃ©ploiement / Serveur de Flow**
* les **Workers** qui exÃ©cutent les tÃ¢ches

Câ€™est ce dÃ©coupage qui explique pourquoi **plusieurs terminaux** sont nÃ©cessaires.

---

# ğŸš€ 1. PrÃ©requis

Installer si besoin les dÃ©pendances:

```bash
poetry install
```

```bash
docker compose up -d
poetry run prefect config set PREFECT_API_URL="http://127.0.0.1:4200/api"
poetry run prefect config set PREFECT_API_DATABASE_CONNECTION_URL="postgresql+asyncpg://prefect:prefect@localhost:5433/prefect"

```
Vous pourrez ensuite vÃ©rifier qu'aucun dossier storage/ est crÃ©Ã© dans ~/.prefect/

---

# ğŸ§  Architecture Prefect 3.6 â€” Pourquoi 3 terminaux ?

Prefect fonctionne selon trois rÃ´les complÃ©mentaires :

### ğŸ–¥ï¸ TERMINAL 1 â€” **Serveur Prefect (API + UI)**

Câ€™est le "cerveau".
Il stocke :

* les flows
* les runs
* lâ€™historique
* les logs
* les orchestrations

Sans le serveur â†’ impossible de dÃ©clencher un flow.

```bash
poetry run prefect server start
```

---

### ğŸ­ TERMINAL 2 â€” **Worker**

Le worker exÃ©cute les runs.
Il se connecte au work pool et rÃ©cupÃ¨re les tÃ¢ches Ã  exÃ©cuter.

Il doit savoir oÃ¹ se trouve le serveur â†’ dâ€™oÃ¹ la variable :

```
PREFECT_API_URL=http://127.0.0.1:4200/api
```

Il doit tourner **en continu** comme un job supervisor.

```bash
export PREFECT_API_URL=http://127.0.0.1:4200/api ; poetry run prefect worker start -p default
```

---

### ğŸ•¹ï¸ TERMINAL 3 â€” **DÃ©clenchement dâ€™un run**

Il sert Ã  enregistrer un "deployment" dans prefect et Ã  lancer un run manuel. Il faut d'abord lancer cette commande : 

```bash
poetry run python prefect_flow/deploy.py 
```

Ensuite ton flow sera "inscrit" dans l'interface. Tu peux dÃ©clencher un run manuellement, ou via le CLI prefect :


```bash
poetry run prefect deployment run "full-pipeline/full-pipeline"
```
En cas d'erreur:

```bash
ValueError: ZoneInfo keys may not be absolute paths, got: /UTC
```

Ajouter ceci, par exemple, aux variables d'environnement:

```bash
export TZ=Europe/Paris
```

# DEBUG

if __name__ == "__main__":
    odis_pipeline(
        config_path="datasources.yaml",
        max_concurrency=4,
    )
