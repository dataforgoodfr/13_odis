# Extracteurs de donnÃ©es

Created: March 12, 2025 10:16 AM
type: documentation

Les sources de donnÃ©es utiles au projet sont diverses avec chacune leurs spÃ©cificitÃ©s mais peuvent prÃ©senter certaines caractÃ©ristiques communes : beaucoup sont des sources OpenData exposant des API suivant le standard REST, certaines suivent le standard spÃ©cifique OpendataSoft, la plupart permettent de rÃ©cupÃ©rer des donnÃ©es sous format JSON et CSV, etcâ€¦

Les spÃ©cificitÃ©s de chacune se situent souvent dans la structure de leurs champs, le nom des paramÃ¨tres Ã  passer, les URL Ã  trouver et appeler, les contraintes Ã  respecter :

- taille de fichiers, pagination ( = dÃ©coupage des rÃ©sultats en plusieurs morceaux )
- ne pas dÃ©passer une certaine frÃ©quence dâ€™appels ( throttling )
- certains paramÃ¨tres Ã  passer dans les requÃªtes, des headers Ã  prÃ©ciserâ€¦
- dans certains cas (plutÃ´t rares), prÃ©senter une authentification ( = un mot de passe ou Ã©quivalent)

Pour rendre lâ€™extraction de ces diverses sources facilement extensible (ie permettre de rapidement rajouter des nouvelles sources dâ€™extraction sans trop de code) tout ne restant assez flexible pour sâ€™adapter aux spÃ©cificitÃ©s de chacune, nous avons adoptÃ© une approche basÃ©e sur des configurations dÃ©claratives, et des objets Extracteurs.

La configuration dÃ©clarative (datasources.yaml) est expliquÃ©e ici : [Config dÃ©clarative des sources](./docs/configurations.md)

## Extractors

Les Extractors sont des classes Python, dÃ©finies dans le fichier `common/utils/source_extractors.py`. Chaque Extractor dÃ©clare une mÃ©thode `extract` servant Ã  requÃªter des API, et rÃ©cupÃ©rer ce qui sort pour le stocker dans un format adÃ©quat (JSON ou CSV par exemple), ou bien le passer Ã  une autre fonction Python qui continuerait la chaÃ®ne dâ€™ELT.

Un Extractor peut Ãªtre assez gÃ©nÃ©rique, pour Ãªtre rÃ©utilisÃ© dans divers cas : `FileExtractor` par exemple, qui rÃ©cupÃ¨re un fichier entier depuis nâ€™importe quelle API http sans authentification ni pagination. Ou au contraire trÃ¨s spÃ©cifique et adaptÃ© Ã  un cas particulier : rÃ©cupÃ©rer une API avec des contraintes trÃ¨s particuliÃ¨res dâ€™authentification, de format, de pagination par exemple.

Les Extractors sont dÃ©rivÃ©s dâ€™une classe abstraite `SourceExtractor` qui dÃ©finit certaines propriÃ©tÃ©s et mÃ©thodes communes, qui sont donc hÃ©ritÃ©es et utilisable par tout Extracteur. En particulier, la fonction `set_query_parameters` qui permet dâ€™interprÃ©ter la configuration dÃ©clarative et prÃ©pare les diffÃ©rents paramÃ¨tres pour envoyer une requÃªte Ã  une API.

## Gestion de la pagination

La plupart des API imposent des contraintes de pagination et de throttling (ou rate limit) : on est alors obligÃ© de rÃ©cupÃ©rer des data en plusieurs pages, avec un appel API par page, et on ne peut pas envoyer plus de â€˜nâ€™ requÃªtes par minute.

Pour gÃ©rer cela, tous les Extractors se comportent comme sâ€™ils allaient paginer, en se basant sur des indications dans la config `datasources.yaml` . Ces indications sont dÃ©finies dans le bloc `response_map` :

```yaml
logements_total:
    API: INSEE.Melodi
    description: nombre de logement
    type: MelodiExtractor
    endpoint: /data/DS_RP_LOGEMENT_PRINC
    format: json
    response_map: # section qui indique comment interpreter des champs de la rÃ©ponse
      data: observations
      next: paging.next # oÃ¹ trouver le champ qui donne la ref de la prochaine page
      is_last: paging.isLast # oÃ¹ trouver le champ qui dit si c'est la derniÃ¨re page
```

Si on dÃ©finit une valeur pour les champs `next` et `is_last` , ils sont rÃ©cupÃ©rÃ©s dans la rÃ©ponse de lâ€™API pour permettre de continuer la pagination.

<aside>
ğŸ’¡

Si on ne dÃ©finit pas les champs `next` ou `is_last` , lâ€™extractor marche, il va juste se comporter comme sâ€™il nâ€™y avait quâ€™une seule page.

</aside>

## Gestion du throttling

Le paramÃ¨tre de throttling est dÃ©fini au niveau de la dÃ©finition dâ€™un bloc `API` et est exprimÃ© en nombre de requÃªtes par minute :

```yaml
INSEE.Melodi:
    name: MELODI
    description: INSEE - API de donnÃ©es locales
    base_url: https://api.insee.fr/melodi
    apidoc: https://portail-api.insee.fr/catalog/api/a890b735-159c-4c91-90b7-35159c7c9126/doc?page=ee625968-272a-4637-a259-68272aa63766
    throttle: 30 # requetes / minutes
    default_headers:
      accept: application/json
```

## Comment ajouter un nouvel Extracteur

Si aucun des Extractors existants dans `common/utils/source_extractors.py` ne convient aux besoins et contraintes de lâ€™API que vous ciblez, vous pouvez soit modifier un Extractor existant, soit en crÃ©er un nouveau adaptÃ© Ã  vos besoins.

Pour crÃ©er un nouvel Extractor, il faut respecter les contraintes suivantes :

1. Tout Extractor doit hÃ©riter de `SourceExtractor`
2. Tout Extractor doit dÃ©finir une mÃ©thode `extract` , qui retourne un **gÃ©nÃ©rateur** python, câ€™est Ã  dire que la fonction ne renvoie pas un â€œreturnâ€, mais un â€œyieldâ€
3. Le gÃ©nÃ©rateur de la mÃ©thode `extract` doit yield la signature suivante : 
    1. `payload` : le contenu de la rÃ©ponse de lâ€™API (json, csv ou autre)
    2. `page_number` (int) : le numÃ©ro de la page quâ€™on vient de rÃ©cupÃ©rer
    3. `is_last` (bool) : est-ce que la page rÃ©cupÃ©rÃ©e Ã©tait la derniÃ¨re
    4. `filepath` (str) : le path vers le fichier dumpÃ© en local, sâ€™il existe

Good luck ğŸ™‚