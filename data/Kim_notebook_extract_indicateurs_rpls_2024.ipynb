{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries and dependencies\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import boto3  # For uploading to AWS S3\n",
    "from io import StringIO\n",
    "\n",
    "# Function to download data from a specific sheet and extract the necessary columns and store those columns as a df\n",
    "def extract_sheet_data(url, sheet_name, columns_to_extract, skiprows=5):\n",
    "    # Download the Excel file\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise an error if the download fails\n",
    "\n",
    "    # Read the Excel file\n",
    "    xlsx = pd.ExcelFile(BytesIO(response.content), engine=\"openpyxl\")\n",
    "\n",
    "    # Load the specific sheet and extract only the necessary columns\n",
    "    df = pd.read_excel(xlsx, sheet_name=sheet_name, skiprows=skiprows)\n",
    "    \n",
    "    # Extract only the required columns for that sheet\n",
    "    df_filtered = df[columns_to_extract]\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "\n",
    "# Function to upload DataFrame to S3 in JSON format\n",
    "def upload_to_s3(df, bucket_name, file_name):\n",
    "    # Convert the DataFrame to JSON format\n",
    "    json_buffer = StringIO()\n",
    "    df.to_json(json_buffer, orient='records', lines=True)  # 'records' format, one JSON object per line\n",
    "    \n",
    "    # Initialize S3 client\n",
    "    s3_client = boto3.client('s3')\n",
    "    \n",
    "    # Upload the JSON data to S3\n",
    "    s3_client.put_object(Bucket=bucket_name, Key=file_name, Body=json_buffer.getvalue())\n",
    "\n",
    "# URL of the Excel file that contains data (for social housing in France from January 2 2023 to January 1 2024)\n",
    "url = \"https://www.statistiques.developpement-durable.gouv.fr/media/7970/download?inline\"\n",
    "\n",
    "# Define the columns to extract for each sheet\n",
    "columns_region = ['REG', 'LIBREG', 'densite', 'nb_ls', 'tx_vac', 'tx_mob']  # Columns for REGION sheet\n",
    "columns_departement = ['REG', 'DEP', 'Unnamed: 1', 'densite', 'nb_ls', 'tx_vac', 'tx_mob']  # Columns for DEPARTEMENT sheet, column 'Unnamed: 1' \n",
    "                                                                                            # corresponds to the column containing the name department name, \n",
    "                                                                                            # the column name will be change to 'LIBDEP' later in current notebook\n",
    "columns_commune = ['REG', 'DEP', 'DEPCOM_ARM', 'LIBCOM', 'densite', 'nb_ls', 'tx_vac', 'tx_mob']  # Columns for COMMUNE sheet\n",
    "# Here is a legend regarding what info is represented in each:\n",
    "    # 'REG' = numéro de la région\n",
    "    # 'LIBREG' = nom de la région\n",
    "    # 'DEP' = numéro du département\n",
    "    # 'Unnamed: 1' = nom du département, will be renamed to 'LIBDEP'\n",
    "    # 'DEPCOM_ARM' = code commune INSEE (ressemble à un code postal mais ça ne l'est pas)\n",
    "    # 'LIBCOM' = nom de la commune' \n",
    "    # 'densite' = Densité de logements sociaux pour 100 résidences principales, source datant du RPLS 2021\n",
    "    # 'nb_ls' = l’ensemble du parc social (en additionnant le nombre de logement proposé  à la location (vide ou loué), le nombre de logement vide pris en charge par une association, le nombre de logement occupé avec ou sans contrepartie financière et le nombre de logement occupé pour de l'hébergement temporaire)\n",
    "    # 'tx_vac' = taux de vacance : pourcentage de vacances des logements proposés à la location au 1er janvier du n-1\n",
    "    # 'tx_mob' = taux de mobilité: pourcentage d’emménagements dans les logements proposés à la location\n",
    "\n",
    "# Extract data for each sheet using the defined columns\n",
    "df_region = extract_sheet_data(url, \"REGION\", columns_region)\n",
    "df_departement = extract_sheet_data(url, \"DEPARTEMENT\", columns_departement)\n",
    "df_commune = extract_sheet_data(url, \"COMMUNES\", columns_commune)\n",
    "\n",
    "\n",
    "# S3 Bucket Name (need to change this to the ODIS's S3 bucket name)\n",
    "bucket_name = 'insert_bucket_name_here'\n",
    "\n",
    "# Upload the DataFrames to S3 as JSON files\n",
    "upload_to_s3(df_region, bucket_name, 'region_data.json')\n",
    "upload_to_s3(df_departement, bucket_name, 'departement_data.json')\n",
    "upload_to_s3(df_commune, bucket_name, 'commune_data.json')\n",
    "\n",
    "print(\"Files uploaded successfully to S3.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
